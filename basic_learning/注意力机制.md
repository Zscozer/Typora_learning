# 注意力机制

## Query and Key

Query :随意线索

Key:不随意线索

![](../picture/随意线索 不随意线索.png)

## 机制

![注意力机制](../picture/注意力机制.png)



## 非参数注意力（不可学习）

![非参数注意力池化层](../picture/非参数注意力池化层.png)

## ![核函数](../picture/核函数.png)

## 参数化注意力机制（可学习）

![参数化注意力](../picture/参数化注意力.png)

## little summary

注意力机制中，通过query（随意线索）和key（不随意线索）来有偏向性的选择输入

以上描述的方法是对于单个量，如果拓展到高维向量怎么做呢，请看下面







## 注意力分数

![注意力分数](../picture/注意力分数.png)

![高维度注意力](../picture/高维度注意力.png)

方法一：有参数

![additive attention](../picture/additive attention.png)

很好理解，就是将q和k合并起来放在全连接层，1层,h个输入，1个输出

方法二：无参数![scaled dot-product](../picture/scaled dot-product.png)

## little summary

![注意力分数总结](../picture/注意力分数总结.png)